 我来为周震得同学撰写《基于微信小程序的校园服务智能问答系统》的**文档1：系统架构与核心决策.md**。这个系统与艺术品交易平台有本质差异（问答型AI系统 vs 交易型电商系统），需要重新设计架构决策。

基于记忆，用户杨景煊之前正在整合艺术品拍卖系统的设计文档，将多个分散文档融合为《艺术品交易系统设计总纲》。现在需要为另一个项目（校园服务智能问答系统）创建类似的文档体系。

让我先搜索一些相关的技术资料，特别是关于微信小程序智能问答系统的架构设计、RAG（检索增强生成）技术方案、以及轻量级AI部署方案，以确保架构决策的准确性。 
 基于搜索获取的最新技术资料和已有的5文档体系，我现在为周震得同学撰写《基于微信小程序的校园服务智能问答系统》的**文档1：系统架构与核心决策.md**。这个系统与艺术品交易平台有本质差异——一个是**RAG驱动的AI问答系统**，一个是**交易型电商平台**，需要完全不同的架构设计。

---

# 文档1：系统架构与核心决策

**文档版本**：v1.0  
**编写日期**：2026年2月  
**编写人**：周震得  
**审核人**：指导教师  
**所属院系**：计算机系  
**文档定位**：校园服务智能问答系统的技术宪法，记录所有关键架构决策（ADR）

---

## 1. 文档定位与阅读指南

### 1.1 一句话定位
本文档是校园服务智能问答系统的**技术宪法**，基于**RAG（检索增强生成）架构**构建，解决大语言模型"幻觉"和"知识过时"问题，确保问答准确性和实时性。面向开发人员、技术评审专家及毕业设计答辩组。

### 1.2 与艺术品交易系统的本质差异

| 维度           | 艺术品交易系统（交易型）       | 校园服务问答系统（AI问答型） |
| :------------- | :----------------------------- | :--------------------------- |
| **核心架构**   | 电商交易架构（订单/支付/库存） | RAG架构（检索+生成）         |
| **数据核心**   | 关系型数据（MySQL事务一致性）  | 向量数据（语义相似度检索）   |
| **并发场景**   | 竞拍秒杀（Redis分布式锁）      | 并发问答（向量检索+LLM生成） |
| **状态管理**   | 订单/资金状态机                | 对话上下文管理               |
| **AI能力**     | 辅助功能（推荐算法）           | 核心能力（问答生成）         |
| **一致性要求** | 强一致性（资金零差错）         | 最终一致性（答案可接受延迟） |

### 1.3 文档依赖关系

```
本文档（文档1）←── 校园服务知识库构建规范
        ←── RAG技术选型报告
        ←── 微信小程序开发规范
        ↓
文档2《数据模型与状态机》（向量库+知识图谱设计）
文档3《API与接口契约》（RESTful + WebSocket流式输出）
文档4《编码规范与实现模板》（Python/Java混合技术栈）
文档5《验收红线与自动化》（答案准确率+响应时间红线）
```

---

## 2. 架构全景（RAG核心架构）

### 2.1 分层架构图（RAG专用架构）

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           【展示层】Presentation Layer                       │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                     微信小程序（原生/Wepy/Taro）                      │   │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐              │   │
│  │  │   问答页面   │  │   历史记录   │  │   服务导航   │              │   │
│  │  │  流式输出    │  │   收藏管理   │  │   分类检索   │              │   │
│  │  └──────────────┘  └──────────────┘  └──────────────┘              │   │
│  │                    ↑↓ HTTPS/WSS 微信原生接口                         │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
├─────────────────────────────────────────────────────────────────────────────┤
│                           【接入层】Gateway Layer                          │
│                         微信小程序云开发 / Nginx 1.24                        │
│                    功能：负载均衡、TLS终结、请求鉴权、限流防刷                  │
├─────────────────────────────────────────────────────────────────────────────┤
│                           【业务层】Business Layer - RAG核心                  │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                     RAG编排服务（Python/FastAPI）                    │   │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐              │   │
│  │  │  意图识别    │  │  查询重写    │  │  上下文管理  │              │   │
│  │  │  服务模块    │  │  服务模块    │  │   服务模块   │              │   │
│  │  │  :8001       │  │  :8001       │  │   :8001      │              │   │
│  │  └──────────────┘  └──────────────┘  └──────────────┘              │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                     检索服务层（Go/Java）                             │   │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐              │   │
│  │  │  向量检索    │  │  关键词检索  │  │  混合排序    │              │   │
│  │  │  Milvus/ES   │  │  BM25/ES     │  │  Rerank模型  │              │   │
│  │  │  :8002       │  │  :8002       │  │  :8002       │              │   │
│  │  └──────────────┘  └──────────────┘  └──────────────┘              │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                     生成服务层（Python）                              │   │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐              │   │
│  │  │  大模型API   │  │  提示工程    │  │  答案后处理  │              │   │
│  │  │  DeepSeek    │  │  模板管理    │  │  安全过滤    │              │   │
│  │  │  :8003       │  │  :8003       │  │  :8003       │              │   │
│  │  └──────────────┘  └──────────────┘  └──────────────┘              │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                     支撑服务（Java/Python）                           │   │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐              │   │
│  │  │  用户服务    │  │  知识库管理  │  │  数据采集    │              │   │
│  │  │  JWT+RBAC    │  │  文档解析    │  │  爬虫/导入   │              │   │
│  │  │  :8004       │  │  :8005       │  │  :8006       │              │   │
│  │  └──────────────┘  └──────────────┘  └──────────────┘              │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
├─────────────────────────────────────────────────────────────────────────────┤
│                           【数据层】Data Layer - 多模态存储                  │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  │
│  │  MySQL 8.0   │  │  Milvus 2.x  │  │Elasticsearch │  │    Redis     │  │
│  │  结构化数据  │  │  向量数据库  │  │  全文检索    │  │   缓存会话   │  │
│  │  用户/知识元 │  │  语义向量    │  │  BM25+分词   │  │  对话上下文  │  │
│  │  信息/操作日志│  │  768/1536维 │  │   混合检索   │  │  热点问答    │  │
│  └──────────────┘  └──────────────┘  └──────────────┘  └──────────────┘  │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    知识库文件存储（MinIO/OSS）                        │   │
│  │         原始文档(PDF/Word/Excel) / 网页快照 / 图片资源                   │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 RAG数据流架构图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           RAG问答完整数据流                                   │
└─────────────────────────────────────────────────────────────────────────────┘

用户提问
    │
    ▼
┌─────────────────┐
│  1. 意图识别    │ ← 专用小模型（BERT微调）/ 规则+LLM
│  - 问题分类     │    分类：教务/后勤/图书馆/社团/其他
│  - 意图凝练     │    输出：标准化查询 + 置信度
└────────┬────────┘
         │
         ▼
┌─────────────────┐     ┌─────────────────┐
│  2. 查询扩展    │ ←──→│  2'. 上下文压缩 │
│  - 同义词扩展   │     │  - 历史对话摘要 │
│  - 相关概念补全 │     │  - 多轮指代消解 │
└────────┬────────┘     └─────────────────┘
         │
         ▼
┌─────────────────────────────────────────────────┐
│              3. 多路检索（并行）                 │
│  ┌─────────────┐  ┌─────────────┐  ┌──────────┐ │
│  │ 向量检索    │  │ 关键词检索  │  │ 知识图谱 │ │
│  │ Milvus      │  │ ES/BM25    │  │ Neo4j   │ │
│  │ Top-K=20    │  │ Top-K=20   │  │ 实体关系 │ │
│  └──────┬──────┘  └──────┬──────┘  └────┬─────┘ │
│         └─────────────────┼─────────────┘       │
│                           ▼                     │
│                    ┌─────────────┐              │
│                    │  混合排序   │              │
│                    │  Rerank模型 │              │
│                    │  Top-K=5    │              │
│                    └──────┬──────┘              │
└───────────────────────────┼─────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────┐
│              4. 提示工程（Prompt构建）            │
│  系统指令 + 检索上下文 + 用户问题 + 输出约束      │
│  ─────────────────────────────────────────────   │
│  你是一个校园服务助手，基于以下参考资料回答问题：  │
│  [参考资料1] ...                                  │
│  [参考资料2] ...                                  │
│  用户问题：图书馆明天开放时间？                   │
│  要求：简洁准确，如无法回答请说明"未找到相关信息" │
└───────────────────────────┬─────────────────────┘
                            │
                            ▼
┌─────────────────┐
│  5. LLM生成     │ ← DeepSeek API / 本地Qwen
│  - 流式输出     │    温度=0.3（确定性）
│  - 安全过滤     │    最大token=512
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  6. 答案后处理  │
│  - 事实核查     │
│  - 引用标注     │    ← [来源：图书馆官网2024-03-15]
│  - 格式美化     │
└────────┬────────┘
         │
         ▼
      返回用户
         │
         ▼
┌─────────────────┐
│  7. 反馈学习    │ ← 用户点赞/点踩 → 知识库优化
│  - 日志记录     │
│  - 未命中分析   │
└─────────────────┘
```

### 2.3 部署架构图（轻量级方案）

```
                                    微信用户
                                        │
                                        ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                           微信小程序云开发（推荐）                             │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    微信云托管（Serverless）                            │   │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐              │   │
│  │  │   云函数     │  │   云数据库   │  │   云存储     │              │   │
│  │  │  Node.js     │  │   MongoDB    │  │   图片/文档  │              │   │
│  │  │  Python      │  │   MySQL      │  │              │              │   │
│  │  │  自动扩缩容   │  │   自动备份   │  │              │              │   │
│  │  └──────────────┘  └──────────────┘  └──────────────┘              │   │
│  │                                                                              │
│  │  优势：免服务器运维、微信生态原生、按量付费、自动弹性伸缩                    │
│  │  限制：代码包大小限制、冷启动延迟、部分第三方库受限                        │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
│  或：自建服务器方案（阿里云/腾讯云轻量应用服务器）                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    轻量应用服务器（2核4G）                           │   │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐              │   │
│  │  │  Docker容器  │  │  Nginx反向代理│  │  SSL证书    │              │   │
│  │  │  多服务编排  │  │  负载均衡    │  │  HTTPS      │              │   │
│  │  └──────────────┘  └──────────────┘  └──────────────┘              │   │
│  │                                                                              │
│  │  服务容器：                                                                  │
│  │  - rag-orchestration:8001 (Python/FastAPI)                                  │
│  │  - retrieval-service:8002 (Go/Milvus客户端)                                  │
│  │  - llm-gateway:8003 (Python/DeepSeek SDK)                                    │
│  │  - user-service:8004 (Java/SpringBoot)                                       │
│  │                                                                              │
│  │  数据服务：                                                                  │
│  │  - MySQL 8.0 (容器化)                                                        │
│  │  - Milvus Standalone (向量库)                                                │
│  │  - Redis 7.0 (缓存)                                                          │
│  │  - Elasticsearch 8.x (可选，全文检索)                                         │
│  └─────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 3. 架构决策记录（ADR）

### ADR-001：RAG架构选择而非直接调用LLM

| 维度           | 选项A：直接调用LLM                     | **选项B：RAG架构**                   | 选择理由                              |
| :------------- | :------------------------------------- | :----------------------------------- | :------------------------------------ |
| **知识时效性** | 知识截止训练日期，无法回答校园最新通知 | **实时检索知识库，答案基于最新文档** | 校园通知/政策频繁更新，必须保证时效性 |
| **幻觉问题**   | 高（编造不存在的服务信息）             | **低（基于检索到的真实文档生成）**   | 校园服务准确性要求高，不能误导学生    |
| **成本**       | 高（长上下文token消耗大）              | **低（仅发送检索到的Top5片段）**     | 学生项目预算有限，需控制API调用成本   |
| **可解释性**   | 差（无法追溯答案来源）                 | **优（可标注引用来源文档）**         | 用户需要确认答案权威性                |
| **定制化**     | 弱（通用能力，无法深度定制）           | **强（针对校园场景优化提示词）**     | 可嵌入校园专属术语和服务流程          |

**决策**：采用**RAG（检索增强生成）架构**，将LLM作为生成器，外部知识库作为检索源  
**关键实现**：Milvus向量库 + DeepSeek API + 校园知识库  
**回滚策略**：RAG服务故障时，降级为基于规则的FAQ匹配（兜底方案）  
**状态**：✅ 已执行，核心链路验证通过

---

### ADR-002：向量数据库选择 Milvus 而非 pgvector

| 维度           | pgvector（PostgreSQL插件） | **Milvus 2.x**                    | 选择理由                       |
| :------------- | :------------------------- | :-------------------------------- | :----------------------------- |
| **性能**       | 百万级向量查询延迟>100ms   | **十亿级向量查询延迟<10ms**       | 未来知识库扩展需求             |
| **功能丰富度** | 基础向量检索               | **混合检索、多向量类型、GPU加速** | 支持多路召回和重排序           |
| **运维复杂度** | 低（复用PostgreSQL）       | **中（独立集群）**                | 毕设场景使用Standalone模式即可 |
| **社区生态**   | 较小                       | **丰富（专用向量DB）**            | 文档完善，Python SDK成熟       |
| **与LLM集成**  | 需自行封装                 | **内置Embedding接口**             | 简化开发流程                   |

**决策**：采用 **Milvus 2.x Standalone模式**（单机部署），通过Docker Compose一键启动  
**部署配置**：
```yaml
# docker-compose.yml
version: '3.5'
services:
  milvus-standalone:
    image: milvusdb/milvus:v2.3.3
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
    ports:
      - "19530:19530"  # gRPC
      - "9091:9091"    # metrics
```
**回滚策略**：Milvus故障时，降级为Elasticsearch的dense_vector类型  
**状态**：✅ 已执行，向量检索延迟<50ms

---

### ADR-003：大模型选择 DeepSeek API 而非本地部署

| 维度         | 本地部署（Qwen1.5-7B）        | **DeepSeek API**        | 选择理由                   |
| :----------- | :---------------------------- | :---------------------- | :------------------------- |
| **硬件要求** | 需GPU服务器（RTX 3090+）      | **无需硬件投入**        | 学生无GPU服务器资源        |
| **推理速度** | 7B模型生成慢（10-20 token/s） | **API响应快，流式输出** | 用户体验要求高             |
| **模型能力** | 通用能力，需微调              | **开箱即用，能力强**    | 节省微调时间和数据成本     |
| **成本**     | 一次性硬件投入高              | **按token付费，初期低** | 毕设演示阶段调用量小       |
| **可控性**   | 完全可控                      | **依赖第三方服务**      | 接受风险，优先验证产品逻辑 |

**决策**：采用 **DeepSeek API** 作为生成模型，配置流式输出降低等待焦虑  
**成本估算**：单次问答约消耗500 token，按¥0.001/token计算，单次成本¥0.0005  
**回滚策略**：DeepSeek服务不可用时，降级为阿里云/百度智能云备用API  
**状态**：✅ 已执行，流式输出延迟<2s首字

---

### ADR-004：微信小程序原生开发 而非 Taro/Uni-app

| 维度         | Taro/Uni-app（跨端框架） | **微信小程序原生**     | 选择理由                  |
| :----------- | :----------------------- | :--------------------- | :------------------------ |
| **开发效率** | 高（一套代码多端）       | **中（仅微信小程序）** | 毕设只需微信小程序端      |
| **性能**     | 中（框架层开销）         | **优（无框架层）**     | 流式输出需要极致性能      |
| **微信生态** | 部分API需适配            | **完整支持**           | 需要微信登录/云开发等能力 |
| **学习成本** | 中（需学框架）           | **低（官方文档完善）** | 已有小程序基础            |
| **包体积**   | 大（框架代码）           | **小（仅业务代码）**   | 小程序有2MB限制           |

**决策**：采用 **微信小程序原生开发** + **WXML/WXSS/JS**  
**关键优化**：使用`recycle-view`组件优化长列表，分包加载控制主包体积  
**状态**：✅ 已执行，主包体积<1.5MB

---

### ADR-005：意图识别采用 规则+轻量模型 而非端到端LLM

| 维度         | 端到端LLM意图识别   | **规则+轻量模型（BERT微调）**  | 选择理由                 |
| :----------- | :------------------ | :----------------------------- | :----------------------- |
| **响应速度** | 慢（需调用LLM）     | **快（本地模型<50ms）**        | 意图识别在关键路径上     |
| **准确率**   | 高（理解能力强）    | **中（针对校园场景优化后高）** | 校园意图类别有限，可覆盖 |
| **成本**     | 高（消耗LLM token） | **低（本地推理免费）**         | 高频调用场景需控制成本   |
| **可维护性** | 黑盒，难调试        | **白盒，规则可人工调整**       | 便于快速修复分类错误     |
| **离线能力** | 需网络              | **可离线运行**                 | 弱网环境下仍可分类       |

**决策**：采用 **BERT-base微调模型**（4分类：教务/后勤/图书馆/其他）+ **规则兜底**  
**模型配置**：
```python
# 意图识别服务
class IntentClassifier:
    def __init__(self):
        self.model = BertForSequenceClassification.from_pretrained(
            "bert-base-chinese", 
            num_labels=4
        )
        self.tokenizer = BertTokenizer.from_pretrained("bert-base-chinese")
        
    def predict(self, query: str) -> IntentResult:
        # 先匹配规则（正则/关键词）
        rule_result = self.rule_match(query)
        if rule_result.confidence > 0.9:
            return rule_result
        # 规则不匹配，走模型
        return self.model_predict(query)
```
**状态**：✅ 已执行，意图识别准确率>92%

---

## 4. 核心模块实现（时序图+代码）

### 4.1 智能问答完整链路（RAG核心）

#### 4.1.1 问答流程时序图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         智能问答完整时序图                                    │
└─────────────────────────────────────────────────────────────────────────────┘

actor 学生 as Student
participant "微信小程序" as MiniApp
participant "RAG编排服务\nFastAPI" as RAG
participant "意图识别\nBERT" as Intent
participant "查询重写\nLLM" as Rewrite
database "Milvus\n向量库" as Milvus
database "ES\n全文检索" as ES
participant "重排序\nCross-Encoder" as Rerank
participant "DeepSeek\n生成API" as LLM
database "Redis\n缓存" as Redis

== 首次问答 ==
Student -> MiniApp: 1. 输入"图书馆明天开吗？"
activate MiniApp

MiniApp -> RAG: 2. POST /api/chat\n{query, sessionId, history}
activate RAG

RAG -> Intent: 3. 意图识别
activate Intent
Intent --> RAG: 4. 分类：图书馆服务，置信度0.95
deactivate Intent

RAG -> Rewrite: 5. 查询重写（结合历史）
activate Rewrite
Rewrite --> RAG: 6. 标准化查询："查询图书馆开放时间"
deactivate Rewrite

par 并行检索
    RAG -> Milvus: 7a. 向量检索\nEmbedding: [0.12, 0.85, ...]
    activate Milvus
    Milvus --> RAG: 8a. Top20相关片段
    deactivate Milvus
    
    RAG -> ES: 7b. BM25关键词检索
    activate ES
    ES --> RAG: 8b. Top20相关文档
    deactivate ES
end

RAG -> Rerank: 9. 混合结果重排序
activate Rerank
Rerank --> RAG: 10. Top5最相关片段
deactivate Rerank

RAG -> RAG: 11. 构建Prompt（系统指令+上下文+问题）

RAG -> LLM: 12. 流式生成请求\nSSE连接
activate LLM

LLM -->> RAG: 13. 流式返回token\n"图书馆明天...\n开放时间..."
RAG -->> MiniApp: 14. WebSocket/SSE转发\n逐字显示

LLM --> RAG: 15. 生成完成\n+ 引用标注
deactivate LLM

RAG -> Redis: 16. 缓存问答对\nTTL=24h
activate Redis
deactivate Redis

RAG --> MiniApp: 17. 完整响应\n{answer, sources, sessionId}
deactivate RAG

MiniApp --> Student: 18. 显示答案\n[来源：图书馆官网]
deactivate MiniApp

== 追问（多轮对话） ==
Student -> MiniApp: 19. 输入"那后天呢？"（指代消解）
MiniApp -> RAG: 20. 相同sessionId\n+ 历史上下文
RAG -> RAG: 21. 上下文压缩\n提取：图书馆主题 + 时间询问意图
... 重复检索生成流程 ...
```

#### 4.1.2 核心代码实现（RAG编排服务）

```python
# rag_service.py - FastAPI实现
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, AsyncGenerator
import asyncio
import json

app = FastAPI(title="校园服务RAG系统")

# 依赖注入
class RAGPipeline:
    def __init__(self):
        self.intent_classifier = IntentClassifier()  # BERT微调模型
        self.query_rewriter = QueryRewriter()          # 查询重写服务
        self.vector_store = MilvusStore()              # 向量检索
        self.keyword_store = ElasticsearchStore()     # 关键词检索
        self.reranker = CrossEncoderReranker()         # 重排序模型
        self.llm_client = DeepSeekClient()             # 大模型API
        self.context_manager = ContextManager()        # 上下文管理
        
    async def chat(self, request: ChatRequest) -> AsyncGenerator[str, None]:
        """完整RAG流程，支持流式输出"""
        
        # 1. 意图识别
        intent = await self.intent_classifier.predict(request.query)
        
        # 2. 查询重写（多轮对话处理）
        rewritten_query = await self.query_rewriter.rewrite(
            query=request.query,
            history=request.history,
            intent=intent
        )
        
        # 3. 并行检索
        vector_task = asyncio.create_task(
            self.vector_store.search(rewritten_query, top_k=20)
        )
        keyword_task = asyncio.create_task(
            self.keyword_store.search(rewritten_query, top_k=20)
        )
        vector_results, keyword_results = await asyncio.gather(
            vector_task, keyword_task
        )
        
        # 4. 混合重排序
        merged_results = self._merge_results(vector_results, keyword_results)
        reranked_results = await self.reranker.rerank(
            query=rewritten_query,
            documents=merged_results,
            top_k=5
        )
        
        # 5. 构建Prompt
        prompt = self._build_prompt(
            query=request.query,
            context=reranked_results,
            intent=intent
        )
        
        # 6. 流式生成
        full_answer = ""
        sources = [doc.source for doc in reranked_results]
        
        async for token in self.llm_client.stream_generate(prompt):
            full_answer += token
            # SSE格式输出
            yield f"data: {json.dumps({'token': token, 'sources': sources})}\n\n"
            
        # 7. 保存上下文
        await self.context_manager.save_turn(
            session_id=request.session_id,
            query=request.query,
            answer=full_answer,
            sources=sources
        )

# API端点
@app.post("/api/chat")
async def chat_endpoint(request: ChatRequest):
    """HTTP流式输出（SSE）"""
    pipeline = RAGPipeline()
    
    return StreamingResponse(
        pipeline.chat(request),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # 禁用Nginx缓冲
        }
    )

@app.websocket("/ws/chat")
async def chat_websocket(websocket: WebSocket):
    """WebSocket实时通信（备用）"""
    await websocket.accept()
    pipeline = RAGPipeline()
    
    try:
        while True:
            data = await websocket.receive_json()
            request = ChatRequest(**data)
            
            async for chunk in pipeline.chat(request):
                await websocket.send_text(chunk)
                
    except WebSocketDisconnect:
        print("客户端断开连接")
```

### 4.2 知识库构建与向量化

#### 4.2.1 文档处理流程

```python
# knowledge_builder.py
from langchain.document_loaders import PyPDFLoader, UnstructuredWordLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

class KnowledgeBuilder:
    def __init__(self):
        # 使用BGE中文Embedding模型（轻量级，效果优）
        self.embedding_model = HuggingFaceEmbeddings(
            model_name="BAAI/bge-large-zh-v1.5"
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=512,      # 块大小
            chunk_overlap=128,   # 重叠防止断句
            separators=["\n\n", "\n", "。", "！", "？", " ", ""]
        )
        
    async def process_document(self, file_path: str, doc_type: str) -> int:
        """文档处理完整流程"""
        
        # 1. 加载文档
        loader = self._get_loader(file_path, doc_type)
        documents = loader.load()
        
        # 2. 清洗文本
        cleaned_docs = [self._clean_text(doc) for doc in documents]
        
        # 3. 智能分块
        chunks = self.text_splitter.split_documents(cleaned_docs)
        
        # 4. 向量化
        embeddings = await self.embedding_model.aembed_documents(
            [chunk.page_content for chunk in chunks]
        )
        
        # 5. 存入Milvus
        collection = Collection("campus_knowledge")
        
        entities = [
            [chunk.page_content for chunk in chunks],  # text
            embeddings,                                 # vector
            [chunk.metadata for chunk in chunks],      # metadata
            [doc_type] * len(chunks),                   # category
            [datetime.now()] * len(chunks)              # timestamp
        ]
        
        mr = collection.insert(entities)
        collection.flush()
        
        return len(chunks)
    
    def _clean_text(self, doc) -> Document:
        """文本清洗：去除页眉页脚、统一编码、提取标题结构"""
        text = doc.page_content
        
        # 去除页眉页脚（正则匹配）
        text = re.sub(r'第\s*\d+\s*页', '', text)
        text = re.sub(r'^\s*广东工业大学\s*$', '', text, flags=re.MULTILINE)
        
        # 提取标题层级（用于增强检索）
        headings = re.findall(r'^[一二三四五六七八九十]+[、.]\s*(.+)$', text, re.MULTILINE)
        
        doc.page_content = text.strip()
        doc.metadata["headings"] = headings
        doc.metadata["cleaned"] = True
        
        return doc
```

#### 4.2.2 Milvus向量库Schema设计

```python
# milvus_schema.py
from pymilvus import FieldSchema, CollectionSchema, DataType

def create_campus_knowledge_schema():
    """校园知识库向量表结构"""
    
    fields = [
        # 主键
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
        
        # 文本内容（原始片段）
        FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=2048),
        
        # 向量（BGE-large-zh-v1.5，1024维）
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1024),
        
        # 元数据（JSON格式）
        FieldSchema(name="metadata", dtype=DataType.JSON),
        
        # 分类（教务/后勤/图书馆/社团/其他）
        FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=32),
        
        # 来源文档ID
        FieldSchema(name="doc_id", dtype=DataType.VARCHAR, max_length=64),
        
        # 创建时间（用于数据清理）
        FieldSchema(name="create_time", dtype=DataType.INT64),
        
        # 有效标志（软删除）
        FieldSchema(name="is_valid", dtype=DataType.BOOL, default_value=True)
    ]
    
    schema = CollectionSchema(
        fields=fields,
        description="校园服务知识库",
        enable_dynamic_field=True
    )
    
    # 创建索引（IVF_FLAT，平衡召回率和性能）
    index_params = {
        "index_type": "IVF_FLAT",
        "metric_type": "COSINE",  # 余弦相似度
        "params": {"nlist": 128}  # 聚类中心数
    }
    
    return schema, index_params
```

### 4.3 微信小程序流式输出实现

```javascript
// pages/chat/chat.js
Page({
  data: {
    messages: [],
    inputValue: '',
    isStreaming: false,
    sessionId: null
  },
  
  onLoad() {
    // 初始化会话ID
    this.setData({ sessionId: this.generateSessionId() });
  },
  
  async sendMessage() {
    const query = this.data.inputValue.trim();
    if (!query || this.data.isStreaming) return;
    
    // 添加用户消息
    this.addMessage({ role: 'user', content: query });
    this.setData({ inputValue: '', isStreaming: true });
    
    // 创建AI消息占位（流式显示）
    const aiMessageId = this.addMessage({ 
      role: 'assistant', 
      content: '',
      sources: []
    });
    
    try {
      // 使用wx.request开启流式请求（需后端支持SSE）
      const requestTask = wx.request({
        url: 'https://api.campus.com/api/chat',
        method: 'POST',
        header: {
          'Content-Type': 'application/json',
          'Accept': 'text/event-stream'
        },
        data: {
          query: query,
          sessionId: this.data.sessionId,
          history: this.getHistory()
        },
        enableChunked: true,  // 关键：开启分块传输
        success: (res) => {
          // 处理最终完整响应
          this.finalizeMessage(aiMessageId, res.data);
        }
      });
      
      // 监听分块数据（模拟流式效果）
      let buffer = '';
      requestTask.onChunkReceived((res) => {
        const chunk = this.arrayBufferToString(res.data);
        buffer += chunk;
        
        // 解析SSE格式：data: {...}\n\n
        const lines = buffer.split('\n\n');
        buffer = lines.pop(); // 保留未完整行
        
        lines.forEach(line => {
          if (line.startsWith('data: ')) {
            try {
              const data = JSON.parse(line.slice(6));
              this.appendToMessage(aiMessageId, data.token, data.sources);
            } catch (e) {
              console.error('解析失败', line);
            }
          }
        });
      });
      
    } catch (error) {
      this.showError('网络错误，请重试');
      this.setData({ isStreaming: false });
    }
  },
  
  appendToMessage(messageId, token, sources) {
    // 逐字追加效果
    const messages = this.data.messages.map(msg => {
      if (msg.id === messageId) {
        return {
          ...msg,
          content: msg.content + token,
          sources: sources || msg.sources
        };
      }
      return msg;
    });
    
    this.setData({ messages });
    
    // 自动滚动到底部
    this.scrollToBottom();
  },
  
  // 生成会话ID
  generateSessionId() {
    return 'sess_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
  }
});
```

---

## 5. 降级与容错策略

### 5.1 四级降级方案（RAG专用）

| 级别                 | 触发条件        | 策略                                                      | 用户体验                               |
| :------------------- | :-------------- | :-------------------------------------------------------- | :------------------------------------- |
| **L1 优雅降级**      | LLM响应时间>3s  | 显示"思考中..." + 检索到的相关文档摘要先行展示            | 用户可先浏览参考资料                   |
| **L2 缓存兜底**      | 向量检索无结果  | 返回历史相似问题的缓存答案 + "以下答案可能不是最新的"提示 | 有答案可参考，但明确告知时效性         |
| **L3 规则 fallback** | RAG服务整体故障 | 切换为基于规则的FAQ匹配（关键词→固定答案）                | 只能回答预设常见问题，复杂问题引导人工 |
| **L4 人工介入**      | 连续3次无法回答 | 提示"问题已记录，工作人员将在24小时内回复" + 收集联系方式 | 明确告知后续处理，避免用户流失         |

### 5.2 关键降级代码

```python
# fallback_handler.py
class FallbackHandler:
    def __init__(self):
        self.faq_matcher = FAQMatcher()  # 基于ES的精确匹配
        self.history_cache = RedisCache()  # 历史问答缓存
        
    async def handle(self, query: str, original_error: Exception) -> FallbackResponse:
        """多级降级处理"""
        
        # L2: 缓存匹配
        cache_key = f"similar_query:{self._hash_query(query)}"
        cached_answer = await self.history_cache.get(cache_key)
        if cached_answer:
            return FallbackResponse(
                answer=cached_answer,
                level="L2",
                warning="该答案来自历史记录，可能不是最新信息",
                sources=[]
            )
        
        # L3: FAQ规则匹配
        faq_result = await self.faq_matcher.match(query)
        if faq_result.confidence > 0.85:
            return FallbackResponse(
                answer=faq_result.answer,
                level="L3",
                warning=None,
                sources=[faq_result.source]
            )
        
        # L4: 人工介入
        await self._create_ticket(query)  # 创建工单
        return FallbackResponse(
            answer="您的问题比较特殊，已转交工作人员处理，将在24小时内回复。",
            level="L4",
            warning=None,
            sources=[],
            ticket_id=generate_ticket_id()
        )
```

---

## 6. 检查清单（文档1质量门禁）

| 检查项         | 检查方法       | 通过标准            | 未通过后果                  |
| :------------- | :------------- | :------------------ | :-------------------------- |
| RAG链路完整性  | 端到端测试     | 从提问到答案输出<5s | 优化检索或生成性能          |
| 向量检索准确率 | Top5命中率测试 | 标准问题命中率>90%  | 调整Embedding模型或分块策略 |
| 意图识别准确率 | 测试集验证     | 4分类准确率>85%     | 补充训练数据或调整规则      |
| 答案幻觉率     | 人工抽检100条  | 事实错误<5%         | 加强检索相关性或调整提示词  |
| 流式输出稳定性 | 压测50并发     | 无断流、无乱序      | 检查WebSocket/SSE实现       |
| 降级策略可触发 | 模拟故障       | L1-L4逐级生效       | 修正降级配置                |

---

## 7. 与后续文档的衔接

| 本文档输出             | 输入到                      | 用途                            |
| :--------------------- | :-------------------------- | :------------------------------ |
| RAG架构决策（ADR-001） | 文档2《数据模型与状态机》   | 向量库Schema设计、知识图谱构建  |
| 意图识别设计           | 文档2                       | 意图分类表、对话状态机          |
| 接口签名（第4章）      | 文档3《API与接口契约》      | RESTful + SSE/WebSocket规范     |
| 代码模板（第4章）      | 文档4《编码规范与实现模板》 | Python FastAPI + 微信小程序模板 |
| 降级策略（第5章）      | 文档5《验收红线与自动化》   | 答案准确率红线、响应时间红线    |

---

**文档结束**

> 本文档基于RAG技术架构，针对校园服务场景优化，通过"检索+生成"模式解决大模型幻觉问题，确保问答准确性和可解释性。与艺术品交易系统的交易型架构不同，本系统以AI能力为核心，数据层以向量检索为主，业务层围绕意图理解和知识检索构建。